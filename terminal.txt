rakshithram@tihan-B550-AORUS-MASTER:~/SDC_project$ python3 pt_train.py 
pt_train.py:52: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.
  self.data = pd.read_csv(csv_file, sep=' ', names=['filename', 'angle'], index_col=False)
Starting training...
/home/rakshithram/.local/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch [1/30], Batch [0/1596], Loss: 0.3826
Epoch [1/30], Batch [100/1596], Loss: 0.5441
Epoch [1/30], Batch [200/1596], Loss: 0.0936
Epoch [1/30], Batch [300/1596], Loss: 0.5222
Epoch [1/30], Batch [400/1596], Loss: 0.0706
Epoch [1/30], Batch [500/1596], Loss: 0.2425
Epoch [1/30], Batch [600/1596], Loss: 0.3600
Epoch [1/30], Batch [700/1596], Loss: 0.1250
Epoch [1/30], Batch [800/1596], Loss: 0.2568
Epoch [1/30], Batch [900/1596], Loss: 0.6381
Epoch [1/30], Batch [1000/1596], Loss: 0.2893
Epoch [1/30], Batch [1100/1596], Loss: 0.4977
Epoch [1/30], Batch [1200/1596], Loss: 0.2448
Epoch [1/30], Batch [1300/1596], Loss: 0.7936
Epoch [1/30], Batch [1400/1596], Loss: 0.1188
Epoch [1/30], Batch [1500/1596], Loss: 0.0758
 
Epoch 1/30, Train Loss: 0.2033, Validation Loss: 0.1885
 
Epoch [2/30], Batch [0/1596], Loss: 0.1544
Epoch [2/30], Batch [100/1596], Loss: 0.0570
Epoch [2/30], Batch [200/1596], Loss: 0.8266
Epoch [2/30], Batch [300/1596], Loss: 0.1344
Epoch [2/30], Batch [400/1596], Loss: 0.0768
Epoch [2/30], Batch [500/1596], Loss: 0.4641
Epoch [2/30], Batch [600/1596], Loss: 0.0703
Epoch [2/30], Batch [700/1596], Loss: 0.0784
Epoch [2/30], Batch [800/1596], Loss: 0.1134
Epoch [2/30], Batch [900/1596], Loss: 0.4379
Epoch [2/30], Batch [1000/1596], Loss: 0.3491
Epoch [2/30], Batch [1100/1596], Loss: 0.0445
Epoch [2/30], Batch [1200/1596], Loss: 0.2977
Epoch [2/30], Batch [1300/1596], Loss: 0.0794
Epoch [2/30], Batch [1400/1596], Loss: 0.2725
Epoch [2/30], Batch [1500/1596], Loss: 0.0845
 
Epoch 2/30, Train Loss: 0.1561, Validation Loss: 0.1222
 
Epoch [3/30], Batch [0/1596], Loss: 0.0461
Epoch [3/30], Batch [100/1596], Loss: 0.3951
Epoch [3/30], Batch [200/1596], Loss: 0.0973
Epoch [3/30], Batch [300/1596], Loss: 0.0460
Epoch [3/30], Batch [400/1596], Loss: 0.0352
Epoch [3/30], Batch [500/1596], Loss: 0.1153
Epoch [3/30], Batch [600/1596], Loss: 0.0371
Epoch [3/30], Batch [700/1596], Loss: 0.0463
Epoch [3/30], Batch [800/1596], Loss: 0.1199
Epoch [3/30], Batch [900/1596], Loss: 0.0427
Epoch [3/30], Batch [1000/1596], Loss: 0.0625
Epoch [3/30], Batch [1100/1596], Loss: 0.1051
Epoch [3/30], Batch [1200/1596], Loss: 0.0429
Epoch [3/30], Batch [1300/1596], Loss: 0.0483
Epoch [3/30], Batch [1400/1596], Loss: 0.0868
Epoch [3/30], Batch [1500/1596], Loss: 0.0344
 
Epoch 3/30, Train Loss: 0.1102, Validation Loss: 0.0915
 
Epoch [4/30], Batch [0/1596], Loss: 0.2065
Epoch [4/30], Batch [100/1596], Loss: 0.1103
Epoch [4/30], Batch [200/1596], Loss: 0.0366
Epoch [4/30], Batch [300/1596], Loss: 0.1809
Epoch [4/30], Batch [400/1596], Loss: 0.1321
Epoch [4/30], Batch [500/1596], Loss: 0.2555
Epoch [4/30], Batch [600/1596], Loss: 0.2586
Epoch [4/30], Batch [700/1596], Loss: 0.1132
Epoch [4/30], Batch [800/1596], Loss: 0.1252
Epoch [4/30], Batch [900/1596], Loss: 0.0165
Epoch [4/30], Batch [1000/1596], Loss: 0.0356
Epoch [4/30], Batch [1100/1596], Loss: 0.0346
Epoch [4/30], Batch [1200/1596], Loss: 0.0588
Epoch [4/30], Batch [1300/1596], Loss: 0.0462
Epoch [4/30], Batch [1400/1596], Loss: 0.1298
Epoch [4/30], Batch [1500/1596], Loss: 0.0901
 
Epoch 4/30, Train Loss: 0.0845, Validation Loss: 0.0762
 
Epoch [5/30], Batch [0/1596], Loss: 0.0765
Epoch [5/30], Batch [100/1596], Loss: 0.0572
Epoch [5/30], Batch [200/1596], Loss: 0.0690
Epoch [5/30], Batch [300/1596], Loss: 0.2035
Epoch [5/30], Batch [400/1596], Loss: 0.0696
Epoch [5/30], Batch [500/1596], Loss: 0.1999
Epoch [5/30], Batch [600/1596], Loss: 0.1318
Epoch [5/30], Batch [700/1596], Loss: 0.0481
Epoch [5/30], Batch [800/1596], Loss: 0.2484
Epoch [5/30], Batch [900/1596], Loss: 0.1044
Epoch [5/30], Batch [1000/1596], Loss: 0.0559
Epoch [5/30], Batch [1100/1596], Loss: 0.0464
Epoch [5/30], Batch [1200/1596], Loss: 0.0505
Epoch [5/30], Batch [1300/1596], Loss: 0.0939
Epoch [5/30], Batch [1400/1596], Loss: 0.0248
Epoch [5/30], Batch [1500/1596], Loss: 0.0399
 
Epoch 5/30, Train Loss: 0.0645, Validation Loss: 0.0417
 
Epoch [6/30], Batch [0/1596], Loss: 0.0519
Epoch [6/30], Batch [100/1596], Loss: 0.0606
Epoch [6/30], Batch [200/1596], Loss: 0.0196
Epoch [6/30], Batch [300/1596], Loss: 0.0905
Epoch [6/30], Batch [400/1596], Loss: 0.0849
Epoch [6/30], Batch [500/1596], Loss: 0.0495
Epoch [6/30], Batch [600/1596], Loss: 0.0184
Epoch [6/30], Batch [700/1596], Loss: 0.0711
Epoch [6/30], Batch [800/1596], Loss: 0.0589
Epoch [6/30], Batch [900/1596], Loss: 0.0557
Epoch [6/30], Batch [1000/1596], Loss: 0.0304
Epoch [6/30], Batch [1100/1596], Loss: 0.0230
Epoch [6/30], Batch [1200/1596], Loss: 0.1462
Epoch [6/30], Batch [1300/1596], Loss: 0.0210
Epoch [6/30], Batch [1400/1596], Loss: 0.0543
Epoch [6/30], Batch [1500/1596], Loss: 0.1070
 
Epoch 6/30, Train Loss: 0.0526, Validation Loss: 0.0331
 
Epoch [7/30], Batch [0/1596], Loss: 0.0626
Epoch [7/30], Batch [100/1596], Loss: 0.0118
Epoch [7/30], Batch [200/1596], Loss: 0.0580
Epoch [7/30], Batch [300/1596], Loss: 0.0299
Epoch [7/30], Batch [400/1596], Loss: 0.0225
Epoch [7/30], Batch [500/1596], Loss: 0.0438
Epoch [7/30], Batch [600/1596], Loss: 0.0424
Epoch [7/30], Batch [700/1596], Loss: 0.0317
Epoch [7/30], Batch [800/1596], Loss: 0.0132
Epoch [7/30], Batch [900/1596], Loss: 0.0203
Epoch [7/30], Batch [1000/1596], Loss: 0.0216
Epoch [7/30], Batch [1100/1596], Loss: 0.0245
Epoch [7/30], Batch [1200/1596], Loss: 0.0185
Epoch [7/30], Batch [1300/1596], Loss: 0.0492
Epoch [7/30], Batch [1400/1596], Loss: 0.0230
Epoch [7/30], Batch [1500/1596], Loss: 0.0136
 
Epoch 7/30, Train Loss: 0.0462, Validation Loss: 0.0364
 
Epoch [8/30], Batch [0/1596], Loss: 0.0166
Epoch [8/30], Batch [100/1596], Loss: 0.0199
Epoch [8/30], Batch [200/1596], Loss: 0.0248
Epoch [8/30], Batch [300/1596], Loss: 0.0658
Epoch [8/30], Batch [400/1596], Loss: 0.0945
Epoch [8/30], Batch [500/1596], Loss: 0.0872
Epoch [8/30], Batch [600/1596], Loss: 0.0158
Epoch [8/30], Batch [700/1596], Loss: 0.0533
Epoch [8/30], Batch [800/1596], Loss: 0.0279
Epoch [8/30], Batch [900/1596], Loss: 0.0095
Epoch [8/30], Batch [1000/1596], Loss: 0.0453
Epoch [8/30], Batch [1100/1596], Loss: 0.0172
Epoch [8/30], Batch [1200/1596], Loss: 0.0188
Epoch [8/30], Batch [1300/1596], Loss: 0.0336
Epoch [8/30], Batch [1400/1596], Loss: 0.0300
Epoch [8/30], Batch [1500/1596], Loss: 0.0187
 
Epoch 8/30, Train Loss: 0.0428, Validation Loss: 0.0261
 
Epoch [9/30], Batch [0/1596], Loss: 0.0176
Epoch [9/30], Batch [100/1596], Loss: 0.0627
Epoch [9/30], Batch [200/1596], Loss: 0.0789
Epoch [9/30], Batch [300/1596], Loss: 0.0119
Epoch [9/30], Batch [400/1596], Loss: 0.0749
Epoch [9/30], Batch [500/1596], Loss: 0.0138
Epoch [9/30], Batch [600/1596], Loss: 0.0080
Epoch [9/30], Batch [700/1596], Loss: 0.0121
Epoch [9/30], Batch [800/1596], Loss: 0.0693
Epoch [9/30], Batch [900/1596], Loss: 0.0191
Epoch [9/30], Batch [1000/1596], Loss: 0.0143
Epoch [9/30], Batch [1100/1596], Loss: 0.0122
Epoch [9/30], Batch [1200/1596], Loss: 0.0105
Epoch [9/30], Batch [1300/1596], Loss: 0.0367
Epoch [9/30], Batch [1400/1596], Loss: 0.0420
Epoch [9/30], Batch [1500/1596], Loss: 0.0518
 
Epoch 9/30, Train Loss: 0.0385, Validation Loss: 0.0270
 
Epoch [10/30], Batch [0/1596], Loss: 0.1202
Epoch [10/30], Batch [100/1596], Loss: 0.0611
Epoch [10/30], Batch [200/1596], Loss: 0.0123
Epoch [10/30], Batch [300/1596], Loss: 0.0178
Epoch [10/30], Batch [400/1596], Loss: 0.0074
Epoch [10/30], Batch [500/1596], Loss: 0.0242
Epoch [10/30], Batch [600/1596], Loss: 0.0242
Epoch [10/30], Batch [700/1596], Loss: 0.0064
Epoch [10/30], Batch [800/1596], Loss: 0.0105
Epoch [10/30], Batch [900/1596], Loss: 0.0192
Epoch [10/30], Batch [1000/1596], Loss: 0.0228
Epoch [10/30], Batch [1100/1596], Loss: 0.0103
Epoch [10/30], Batch [1200/1596], Loss: 0.0213
Epoch [10/30], Batch [1300/1596], Loss: 0.0128
Epoch [10/30], Batch [1400/1596], Loss: 0.0183
Epoch [10/30], Batch [1500/1596], Loss: 0.0997
 
Epoch 10/30, Train Loss: 0.0340, Validation Loss: 0.0244
 
Epoch [11/30], Batch [0/1596], Loss: 0.0243
Epoch [11/30], Batch [100/1596], Loss: 0.0864
Epoch [11/30], Batch [200/1596], Loss: 0.0173
Epoch [11/30], Batch [300/1596], Loss: 0.0320
Epoch [11/30], Batch [400/1596], Loss: 0.0187
Epoch [11/30], Batch [500/1596], Loss: 0.0257
Epoch [11/30], Batch [600/1596], Loss: 0.0382
Epoch [11/30], Batch [700/1596], Loss: 0.0150
Epoch [11/30], Batch [800/1596], Loss: 0.0164
Epoch [11/30], Batch [900/1596], Loss: 0.0755
Epoch [11/30], Batch [1000/1596], Loss: 0.1569
Epoch [11/30], Batch [1100/1596], Loss: 0.0168
Epoch [11/30], Batch [1200/1596], Loss: 0.0456
Epoch [11/30], Batch [1300/1596], Loss: 0.0158
Epoch [11/30], Batch [1400/1596], Loss: 0.0134
Epoch [11/30], Batch [1500/1596], Loss: 0.0618
 
Epoch 11/30, Train Loss: 0.0333, Validation Loss: 0.0225
 
Epoch [12/30], Batch [0/1596], Loss: 0.0158
Epoch [12/30], Batch [100/1596], Loss: 0.0204
Epoch [12/30], Batch [200/1596], Loss: 0.0059
Epoch [12/30], Batch [300/1596], Loss: 0.0160
Epoch [12/30], Batch [400/1596], Loss: 0.0146
Epoch [12/30], Batch [500/1596], Loss: 0.0212
Epoch [12/30], Batch [600/1596], Loss: 0.0129
Epoch [12/30], Batch [700/1596], Loss: 0.0096
Epoch [12/30], Batch [800/1596], Loss: 0.0127
Epoch [12/30], Batch [900/1596], Loss: 0.0147
Epoch [12/30], Batch [1000/1596], Loss: 0.0146
Epoch [12/30], Batch [1100/1596], Loss: 0.0170
Epoch [12/30], Batch [1200/1596], Loss: 0.0363
Epoch [12/30], Batch [1300/1596], Loss: 0.0495
Epoch [12/30], Batch [1400/1596], Loss: 0.0516
Epoch [12/30], Batch [1500/1596], Loss: 0.0293
 
Epoch 12/30, Train Loss: 0.0301, Validation Loss: 0.0185
 
Epoch [13/30], Batch [0/1596], Loss: 0.0297
Epoch [13/30], Batch [100/1596], Loss: 0.0697
Epoch [13/30], Batch [200/1596], Loss: 0.0153
Epoch [13/30], Batch [300/1596], Loss: 0.0136
Epoch [13/30], Batch [400/1596], Loss: 0.0551
Epoch [13/30], Batch [500/1596], Loss: 0.0449
Epoch [13/30], Batch [600/1596], Loss: 0.0082
Epoch [13/30], Batch [700/1596], Loss: 0.0211
Epoch [13/30], Batch [800/1596], Loss: 0.0277
Epoch [13/30], Batch [900/1596], Loss: 0.0097
Epoch [13/30], Batch [1000/1596], Loss: 0.0869
Epoch [13/30], Batch [1100/1596], Loss: 0.0137
Epoch [13/30], Batch [1200/1596], Loss: 0.0197
Epoch [13/30], Batch [1300/1596], Loss: 0.0176
Epoch [13/30], Batch [1400/1596], Loss: 0.0183
Epoch [13/30], Batch [1500/1596], Loss: 0.0094
 
Epoch 13/30, Train Loss: 0.0313, Validation Loss: 0.0194
 
Epoch [14/30], Batch [0/1596], Loss: 0.0156
Epoch [14/30], Batch [100/1596], Loss: 0.0108
Epoch [14/30], Batch [200/1596], Loss: 0.0066
Epoch [14/30], Batch [300/1596], Loss: 0.0083
Epoch [14/30], Batch [400/1596], Loss: 0.0198
Epoch [14/30], Batch [500/1596], Loss: 0.0070
Epoch [14/30], Batch [600/1596], Loss: 0.4586
Epoch [14/30], Batch [700/1596], Loss: 0.0053
Epoch [14/30], Batch [800/1596], Loss: 0.0610
Epoch [14/30], Batch [900/1596], Loss: 0.0186
Epoch [14/30], Batch [1000/1596], Loss: 0.0115
Epoch [14/30], Batch [1100/1596], Loss: 0.0084
Epoch [14/30], Batch [1200/1596], Loss: 0.0269
Epoch [14/30], Batch [1300/1596], Loss: 0.0735
Epoch [14/30], Batch [1400/1596], Loss: 0.0457
Epoch [14/30], Batch [1500/1596], Loss: 0.0229
 
Epoch 14/30, Train Loss: 0.0279, Validation Loss: 0.0192
 
Epoch [15/30], Batch [0/1596], Loss: 0.0224
Epoch [15/30], Batch [100/1596], Loss: 0.0060
Epoch [15/30], Batch [200/1596], Loss: 0.0891
Epoch [15/30], Batch [300/1596], Loss: 0.0056
Epoch [15/30], Batch [400/1596], Loss: 0.0174
Epoch [15/30], Batch [500/1596], Loss: 0.0053
Epoch [15/30], Batch [600/1596], Loss: 0.0283
Epoch [15/30], Batch [700/1596], Loss: 0.0443
Epoch [15/30], Batch [800/1596], Loss: 0.0050
Epoch [15/30], Batch [900/1596], Loss: 0.0078
Epoch [15/30], Batch [1000/1596], Loss: 0.0100
Epoch [15/30], Batch [1100/1596], Loss: 0.1036
Epoch [15/30], Batch [1200/1596], Loss: 0.0233
Epoch [15/30], Batch [1300/1596], Loss: 0.0036
Epoch [15/30], Batch [1400/1596], Loss: 0.0072
Epoch [15/30], Batch [1500/1596], Loss: 0.0106
 
Epoch 15/30, Train Loss: 0.0255, Validation Loss: 0.0226
 
Epoch [16/30], Batch [0/1596], Loss: 0.0215
Epoch [16/30], Batch [100/1596], Loss: 0.0186
Epoch [16/30], Batch [200/1596], Loss: 0.0079
Epoch [16/30], Batch [300/1596], Loss: 0.0060
Epoch [16/30], Batch [400/1596], Loss: 0.0841
Epoch [16/30], Batch [500/1596], Loss: 0.0183
Epoch [16/30], Batch [600/1596], Loss: 0.0067
Epoch [16/30], Batch [700/1596], Loss: 0.0185
Epoch [16/30], Batch [800/1596], Loss: 0.0105
Epoch [16/30], Batch [900/1596], Loss: 0.0248
Epoch [16/30], Batch [1000/1596], Loss: 0.0108
Epoch [16/30], Batch [1100/1596], Loss: 0.0108
Epoch [16/30], Batch [1200/1596], Loss: 0.0038
Epoch [16/30], Batch [1300/1596], Loss: 0.0154
Epoch [16/30], Batch [1400/1596], Loss: 0.0084
Epoch [16/30], Batch [1500/1596], Loss: 0.0164
 
Epoch 16/30, Train Loss: 0.0257, Validation Loss: 0.0169
 
Epoch [17/30], Batch [0/1596], Loss: 0.0087
Epoch [17/30], Batch [100/1596], Loss: 0.0262
Epoch [17/30], Batch [200/1596], Loss: 0.0666
Epoch [17/30], Batch [300/1596], Loss: 0.0531
Epoch [17/30], Batch [400/1596], Loss: 0.0158
Epoch [17/30], Batch [500/1596], Loss: 0.0451
Epoch [17/30], Batch [600/1596], Loss: 0.0103
Epoch [17/30], Batch [700/1596], Loss: 0.0405
Epoch [17/30], Batch [800/1596], Loss: 0.0728
Epoch [17/30], Batch [900/1596], Loss: 0.0196
Epoch [17/30], Batch [1000/1596], Loss: 0.0211
Epoch [17/30], Batch [1100/1596], Loss: 0.0090
Epoch [17/30], Batch [1200/1596], Loss: 0.0121
Epoch [17/30], Batch [1300/1596], Loss: 0.0136
Epoch [17/30], Batch [1400/1596], Loss: 0.0775
Epoch [17/30], Batch [1500/1596], Loss: 0.0073
 
Epoch 17/30, Train Loss: 0.0239, Validation Loss: 0.0152
 
Epoch [18/30], Batch [0/1596], Loss: 0.0264
Epoch [18/30], Batch [100/1596], Loss: 0.0070
Epoch [18/30], Batch [200/1596], Loss: 0.0452
Epoch [18/30], Batch [300/1596], Loss: 0.0311
Epoch [18/30], Batch [400/1596], Loss: 0.0165
Epoch [18/30], Batch [500/1596], Loss: 0.0076
Epoch [18/30], Batch [600/1596], Loss: 0.0339
Epoch [18/30], Batch [700/1596], Loss: 0.0078
Epoch [18/30], Batch [800/1596], Loss: 0.0083
Epoch [18/30], Batch [900/1596], Loss: 0.0634
Epoch [18/30], Batch [1000/1596], Loss: 0.0033
Epoch [18/30], Batch [1100/1596], Loss: 0.0706
Epoch [18/30], Batch [1200/1596], Loss: 0.0392
Epoch [18/30], Batch [1300/1596], Loss: 0.0199
Epoch [18/30], Batch [1400/1596], Loss: 0.0070
Epoch [18/30], Batch [1500/1596], Loss: 0.0180
 
Epoch 18/30, Train Loss: 0.0242, Validation Loss: 0.0110
 
Epoch [19/30], Batch [0/1596], Loss: 0.0096
Epoch [19/30], Batch [100/1596], Loss: 0.0043
Epoch [19/30], Batch [200/1596], Loss: 0.0268
Epoch [19/30], Batch [300/1596], Loss: 0.0602
Epoch [19/30], Batch [400/1596], Loss: 0.0090
Epoch [19/30], Batch [500/1596], Loss: 0.0246
Epoch [19/30], Batch [600/1596], Loss: 0.0174
Epoch [19/30], Batch [700/1596], Loss: 0.0209
Epoch [19/30], Batch [800/1596], Loss: 0.0138
Epoch [19/30], Batch [900/1596], Loss: 0.0095
Epoch [19/30], Batch [1000/1596], Loss: 0.0075
Epoch [19/30], Batch [1100/1596], Loss: 0.0174
Epoch [19/30], Batch [1200/1596], Loss: 0.0034
Epoch [19/30], Batch [1300/1596], Loss: 0.0169
Epoch [19/30], Batch [1400/1596], Loss: 0.0095
Epoch [19/30], Batch [1500/1596], Loss: 0.0091
 
Epoch 19/30, Train Loss: 0.0229, Validation Loss: 0.0157
 
Epoch [20/30], Batch [0/1596], Loss: 0.0091
Epoch [20/30], Batch [100/1596], Loss: 0.0493
Epoch [20/30], Batch [200/1596], Loss: 0.0206
Epoch [20/30], Batch [300/1596], Loss: 0.0291
Epoch [20/30], Batch [400/1596], Loss: 0.0230
Epoch [20/30], Batch [500/1596], Loss: 0.0426
Epoch [20/30], Batch [600/1596], Loss: 0.0140
Epoch [20/30], Batch [700/1596], Loss: 0.0137
Epoch [20/30], Batch [800/1596], Loss: 0.0061
Epoch [20/30], Batch [900/1596], Loss: 0.0055
Epoch [20/30], Batch [1000/1596], Loss: 0.0051
Epoch [20/30], Batch [1100/1596], Loss: 0.0099
Epoch [20/30], Batch [1200/1596], Loss: 0.0415
Epoch [20/30], Batch [1300/1596], Loss: 0.0130
Epoch [20/30], Batch [1400/1596], Loss: 0.0123
Epoch [20/30], Batch [1500/1596], Loss: 0.0166
 
Epoch 20/30, Train Loss: 0.0222, Validation Loss: 0.0141
 
Epoch [21/30], Batch [0/1596], Loss: 0.0059
Epoch [21/30], Batch [100/1596], Loss: 0.0397
Epoch [21/30], Batch [200/1596], Loss: 0.0068
Epoch [21/30], Batch [300/1596], Loss: 0.0179
Epoch [21/30], Batch [400/1596], Loss: 0.0483
Epoch [21/30], Batch [500/1596], Loss: 0.0092
Epoch [21/30], Batch [600/1596], Loss: 0.0288
Epoch [21/30], Batch [700/1596], Loss: 0.0074
Epoch [21/30], Batch [800/1596], Loss: 0.0213
Epoch [21/30], Batch [900/1596], Loss: 0.0208
Epoch [21/30], Batch [1000/1596], Loss: 0.0218
Epoch [21/30], Batch [1100/1596], Loss: 0.0116
Epoch [21/30], Batch [1200/1596], Loss: 0.0151
Epoch [21/30], Batch [1300/1596], Loss: 0.0078
Epoch [21/30], Batch [1400/1596], Loss: 0.0065
Epoch [21/30], Batch [1500/1596], Loss: 0.0063
 
Epoch 21/30, Train Loss: 0.0226, Validation Loss: 0.0104
 
Epoch [22/30], Batch [0/1596], Loss: 0.0201
Epoch [22/30], Batch [100/1596], Loss: 0.0201
Epoch [22/30], Batch [200/1596], Loss: 0.0242
Epoch [22/30], Batch [300/1596], Loss: 0.0099
Epoch [22/30], Batch [400/1596], Loss: 0.0041
Epoch [22/30], Batch [500/1596], Loss: 0.0240
Epoch [22/30], Batch [600/1596], Loss: 0.0073
Epoch [22/30], Batch [700/1596], Loss: 0.0324
Epoch [22/30], Batch [800/1596], Loss: 0.0125
Epoch [22/30], Batch [900/1596], Loss: 0.0093
Epoch [22/30], Batch [1000/1596], Loss: 0.0144
Epoch [22/30], Batch [1100/1596], Loss: 0.0130
Epoch [22/30], Batch [1200/1596], Loss: 0.0080
Epoch [22/30], Batch [1300/1596], Loss: 0.0257
Epoch [22/30], Batch [1400/1596], Loss: 0.0103
Epoch [22/30], Batch [1500/1596], Loss: 0.0211
 
Epoch 22/30, Train Loss: 0.0219, Validation Loss: 0.0115
 
Epoch [23/30], Batch [0/1596], Loss: 0.0041
Epoch [23/30], Batch [100/1596], Loss: 0.0144
Epoch [23/30], Batch [200/1596], Loss: 0.0144
Epoch [23/30], Batch [300/1596], Loss: 0.0182
Epoch [23/30], Batch [400/1596], Loss: 0.0163
Epoch [23/30], Batch [500/1596], Loss: 0.0144
Epoch [23/30], Batch [600/1596], Loss: 0.0129
Epoch [23/30], Batch [700/1596], Loss: 0.0045
Epoch [23/30], Batch [800/1596], Loss: 0.0103
Epoch [23/30], Batch [900/1596], Loss: 0.0169
Epoch [23/30], Batch [1000/1596], Loss: 0.0166
Epoch [23/30], Batch [1100/1596], Loss: 0.0018
Epoch [23/30], Batch [1200/1596], Loss: 0.0180
Epoch [23/30], Batch [1300/1596], Loss: 0.0069
Epoch [23/30], Batch [1400/1596], Loss: 0.0101
Epoch [23/30], Batch [1500/1596], Loss: 0.0033
 
Epoch 23/30, Train Loss: 0.0206, Validation Loss: 0.0230
 
Epoch [24/30], Batch [0/1596], Loss: 0.0122
Epoch [24/30], Batch [100/1596], Loss: 0.0221
Epoch [24/30], Batch [200/1596], Loss: 0.0141
Epoch [24/30], Batch [300/1596], Loss: 0.0330
Epoch [24/30], Batch [400/1596], Loss: 0.0163
Epoch [24/30], Batch [500/1596], Loss: 0.0135
Epoch [24/30], Batch [600/1596], Loss: 0.0096
Epoch [24/30], Batch [700/1596], Loss: 0.0073
Epoch [24/30], Batch [800/1596], Loss: 0.0201
Epoch [24/30], Batch [900/1596], Loss: 0.0089
Epoch [24/30], Batch [1000/1596], Loss: 0.0084
Epoch [24/30], Batch [1100/1596], Loss: 0.0195
Epoch [24/30], Batch [1200/1596], Loss: 0.0082
Epoch [24/30], Batch [1300/1596], Loss: 0.0062
Epoch [24/30], Batch [1400/1596], Loss: 0.0140
Epoch [24/30], Batch [1500/1596], Loss: 0.0164
 
Epoch 24/30, Train Loss: 0.0221, Validation Loss: 0.0144
 
Epoch [25/30], Batch [0/1596], Loss: 0.0457
Epoch [25/30], Batch [100/1596], Loss: 0.0247
Epoch [25/30], Batch [200/1596], Loss: 0.0058
Epoch [25/30], Batch [300/1596], Loss: 0.0120
Epoch [25/30], Batch [400/1596], Loss: 0.0114
Epoch [25/30], Batch [500/1596], Loss: 0.0396
Epoch [25/30], Batch [600/1596], Loss: 0.0114
Epoch [25/30], Batch [700/1596], Loss: 0.0113
Epoch [25/30], Batch [800/1596], Loss: 0.0174
Epoch [25/30], Batch [900/1596], Loss: 0.0084
Epoch [25/30], Batch [1000/1596], Loss: 0.0092
Epoch [25/30], Batch [1100/1596], Loss: 0.0068
Epoch [25/30], Batch [1200/1596], Loss: 0.0022
Epoch [25/30], Batch [1300/1596], Loss: 0.0226
Epoch [25/30], Batch [1400/1596], Loss: 0.0045
Epoch [25/30], Batch [1500/1596], Loss: 0.0055
 
Epoch 25/30, Train Loss: 0.0191, Validation Loss: 0.0122
 
Epoch [26/30], Batch [0/1596], Loss: 0.0089
Epoch [26/30], Batch [100/1596], Loss: 0.0765
Epoch [26/30], Batch [200/1596], Loss: 0.0071
Epoch [26/30], Batch [300/1596], Loss: 0.0256
Epoch [26/30], Batch [400/1596], Loss: 0.0079
Epoch [26/30], Batch [500/1596], Loss: 0.0046
Epoch [26/30], Batch [600/1596], Loss: 0.0150
Epoch [26/30], Batch [700/1596], Loss: 0.0060
Epoch [26/30], Batch [800/1596], Loss: 0.0118
Epoch [26/30], Batch [900/1596], Loss: 0.0057
Epoch [26/30], Batch [1000/1596], Loss: 0.0059
Epoch [26/30], Batch [1100/1596], Loss: 0.0123
Epoch [26/30], Batch [1200/1596], Loss: 0.0220
Epoch [26/30], Batch [1300/1596], Loss: 0.0118
Epoch [26/30], Batch [1400/1596], Loss: 0.0167
Epoch [26/30], Batch [1500/1596], Loss: 0.0089
 
Epoch 26/30, Train Loss: 0.0197, Validation Loss: 0.0122
 
Epoch [27/30], Batch [0/1596], Loss: 0.0033
Epoch [27/30], Batch [100/1596], Loss: 0.0127
Epoch [27/30], Batch [200/1596], Loss: 0.0093
Epoch [27/30], Batch [300/1596], Loss: 0.0065
Epoch [27/30], Batch [400/1596], Loss: 0.0101
Epoch [27/30], Batch [500/1596], Loss: 0.1996
Epoch [27/30], Batch [600/1596], Loss: 0.0304
Epoch [27/30], Batch [700/1596], Loss: 0.0043
Epoch [27/30], Batch [800/1596], Loss: 0.0076
Epoch [27/30], Batch [900/1596], Loss: 0.0569
Epoch [27/30], Batch [1000/1596], Loss: 0.0054
Epoch [27/30], Batch [1100/1596], Loss: 0.0339
Epoch [27/30], Batch [1200/1596], Loss: 0.0191
Epoch [27/30], Batch [1300/1596], Loss: 0.0339
Epoch [27/30], Batch [1400/1596], Loss: 0.0065
Epoch [27/30], Batch [1500/1596], Loss: 0.0398
 
Epoch 27/30, Train Loss: 0.0196, Validation Loss: 0.0114
 
Epoch [28/30], Batch [0/1596], Loss: 0.0540
Epoch [28/30], Batch [100/1596], Loss: 0.0165
Epoch [28/30], Batch [200/1596], Loss: 0.0768
Epoch [28/30], Batch [300/1596], Loss: 0.0126
Epoch [28/30], Batch [400/1596], Loss: 0.0066
Epoch [28/30], Batch [500/1596], Loss: 0.0259
Epoch [28/30], Batch [600/1596], Loss: 0.0039
Epoch [28/30], Batch [700/1596], Loss: 0.0157
Epoch [28/30], Batch [800/1596], Loss: 0.0233
Epoch [28/30], Batch [900/1596], Loss: 0.0262
Epoch [28/30], Batch [1000/1596], Loss: 0.0296
Epoch [28/30], Batch [1100/1596], Loss: 0.0431
Epoch [28/30], Batch [1200/1596], Loss: 0.0058
Epoch [28/30], Batch [1300/1596], Loss: 0.0019
Epoch [28/30], Batch [1400/1596], Loss: 0.0038
Epoch [28/30], Batch [1500/1596], Loss: 0.0033
 
Epoch 28/30, Train Loss: 0.0199, Validation Loss: 0.0109
 
Epoch [29/30], Batch [0/1596], Loss: 0.0177
Epoch [29/30], Batch [100/1596], Loss: 0.0244
Epoch [29/30], Batch [200/1596], Loss: 0.0062
Epoch [29/30], Batch [300/1596], Loss: 0.0043
Epoch [29/30], Batch [400/1596], Loss: 0.0219
Epoch [29/30], Batch [500/1596], Loss: 0.0060
Epoch [29/30], Batch [600/1596], Loss: 0.0370
Epoch [29/30], Batch [700/1596], Loss: 0.0123
Epoch [29/30], Batch [800/1596], Loss: 0.0108
Epoch [29/30], Batch [900/1596], Loss: 0.0030
Epoch [29/30], Batch [1000/1596], Loss: 0.0047
Epoch [29/30], Batch [1100/1596], Loss: 0.0042
Epoch [29/30], Batch [1200/1596], Loss: 0.0035
Epoch [29/30], Batch [1300/1596], Loss: 0.0059
Epoch [29/30], Batch [1400/1596], Loss: 0.0119
Epoch [29/30], Batch [1500/1596], Loss: 0.0090
 
Epoch 29/30, Train Loss: 0.0179, Validation Loss: 0.0095
 
Epoch [30/30], Batch [0/1596], Loss: 0.0054
Epoch [30/30], Batch [100/1596], Loss: 0.0233
Epoch [30/30], Batch [200/1596], Loss: 0.0191
Epoch [30/30], Batch [300/1596], Loss: 0.0258
Epoch [30/30], Batch [400/1596], Loss: 0.0195
Epoch [30/30], Batch [500/1596], Loss: 0.0250
Epoch [30/30], Batch [600/1596], Loss: 0.0134
Epoch [30/30], Batch [700/1596], Loss: 0.0084
Epoch [30/30], Batch [800/1596], Loss: 0.0059
Epoch [30/30], Batch [900/1596], Loss: 0.0102
Epoch [30/30], Batch [1000/1596], Loss: 0.0680
Epoch [30/30], Batch [1100/1596], Loss: 0.0071
Epoch [30/30], Batch [1200/1596], Loss: 0.0326
Epoch [30/30], Batch [1300/1596], Loss: 0.0205
Epoch [30/30], Batch [1400/1596], Loss: 0.0026
Epoch [30/30], Batch [1500/1596], Loss: 0.0079
 
Epoch 30/30, Train Loss: 0.0183, Validation Loss: 0.0105
 
Model saved to save/final_model.pth
Training complete.